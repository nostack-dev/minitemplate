<!-- ollamachatComponent.html -->
<div id="ollamachatComponent" class="flex flex-col justify-between w-full h-full max-w-2xl mx-auto">
    <!-- Chat bubbles container (scrollable) -->
    <div id="chatContainer" class="flex-1 overflow-y-auto p-4 space-y-4">
        <!-- Messages will be dynamically appended here -->
    </div>
    <!-- Chat input at the bottom -->
    <div class="p-4 border-t border-gray-200">
        <div class="flex items-center gap-2">
            <input type="text" id="userInput" class="input input-bordered flex-grow" placeholder="Enter your message..." onkeypress="handleKeyPress(event)" />
            <button class="btn btn-primary" onclick="sendPrompt()">Send</button>
        </div>
    </div>

    <script>
        // Global variable to hold conversation context
        let context = [];

        // Function to handle Enter key press for sending messages
        function handleKeyPress(event) {
            if (event.key === "Enter") {
                sendPrompt();
            }
        }

        // Function to send a prompt to the AI endpoint
        async function sendPrompt() {
            const inputField = document.getElementById("userInput");
            const userMessage = inputField.value.trim();
            inputField.value = "";

            if (!userMessage) return;

            appendMessage(userMessage, 'user');

            // Add loading indicator while waiting for AI response
            const loadingElement = createLoadingElement();
            const chatContainer = document.getElementById("chatContainer");
            chatContainer.appendChild(loadingElement);
            scrollToBottom();

            // Send the user message to the AI endpoint along with the context
            const requestBody = {
                model: "llama3.2:1b",
                prompt: userMessage,
                context: context  // Include the context from previous conversations
            };

            try {
                const response = await fetch("http://localhost:11434/api/generate", {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify(requestBody)
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! Status: ${response.status}`);
                }

                // Handle streaming response
                const reader = response.body.getReader();
                const decoder = new TextDecoder("utf-8");
                let done = false;
                let tokenBuffer = '';
                let aiResponseText = '';

                while (!done) {
                    const { value, done: readerDone } = await reader.read();
                    done = readerDone;

                    if (value) {
                        tokenBuffer += decoder.decode(value, { stream: true });
                        const tokens = tokenBuffer.split('\n');
                        tokenBuffer = tokens.pop();

                        tokens.forEach(token => {
                            if (token.trim()) {
                                try {
                                    const parsed = JSON.parse(token);
                                    aiResponseText += parsed.response;
                                    loadingElement.textContent = aiResponseText; // Update loading element content
                                    scrollToBottom(); // Ensure autoscroll during streaming

                                    // Update the context from the response
                                    if (parsed.context) {
                                        context = parsed.context;  // Save new context
                                    }
                                } catch (error) {
                                    console.error("Error parsing token:", error);
                                }
                            }
                        });
                    }
                }

                // Replace the loading element with the final AI response
                loadingElement.textContent = aiResponseText;
                scrollToBottom();

            } catch (error) {
                loadingElement.textContent = `Error: ${error.message}`;
                scrollToBottom();
            }
        }

        // Function to create a message element with DaisyUI chat classes
        function createMessageElement(message, sender) {
            const messageElement = document.createElement("div");
            messageElement.classList.add("chat", sender === 'user' ? "chat-end" : "chat-start");

            if (sender === 'user') {
                const bubbleElement = document.createElement("div");
                bubbleElement.classList.add("chat-bubble");
                bubbleElement.textContent = message;
                messageElement.appendChild(bubbleElement);
            } else {
                messageElement.textContent = message;
                messageElement.classList.add("text-secondary-content");
            }

            return messageElement;
        }

        // Function to create a loading indicator
        function createLoadingElement() {
            const loadingElement = document.createElement("div");
            loadingElement.classList.add("chat", "chat-start");
            const spinnerElement = document.createElement("span");
            spinnerElement.classList.add("loading", "loading-ring", "loading-sm");
            loadingElement.appendChild(spinnerElement);
            return loadingElement;
        }

        // Function to append a message
        function appendMessage(message, sender) {
            const messageElement = createMessageElement(message, sender);
            const chatContainer = document.getElementById("chatContainer");
            chatContainer.appendChild(messageElement);
            scrollToBottom();
        }

        // Function to scroll the chat container to the bottom
        function scrollToBottom() {
            const chatContainer = document.getElementById("chatContainer");
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }
    </script>
</div>
